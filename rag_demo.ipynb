{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# LangChain + OpenAI RAG Proof of Concept\n",
       "## Overview\n",
       "* Collates provided sources into local vector store\n",
       "* Persists store for future recovery\n",
       "* Identifies relevant chunks and constructs prompt to send to OpenAI\n",
       "### Dependencies\n",
       "* User account for OpenAI and LangSmith\n",
       "* API keys from OpenAI and LangSmith\n",
       "* Main python dependencies:\n",
       "  * LangChain: langchain-openai langchain-core langchain-text-splitters langchain-community langgraph langchain[openai]\n",
       "  * GDrive: google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-google-community\n",
       "  * Web: bs4 unstructured selenium\n",
       "* Add the following to `~/.bash_profile` or `~/.zprofile` if `~/.zshrc`\n",
       "```\n",
       "export LANGSMITH_TRACING=true\n",
       "export LANGSMITH_ENDPOINT=\"https://{langsmith_region}.api.smith.langchain.com\"\n",
       "export LANGSMITH_API_KEY=\"{your_langsmith_api_key}\"\n",
       "export OPENAI_API_KEY=\"{your_openai_api_key}\"\n",
       "```"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import getpass\n",
       "import os\n",
       "\n",
       "# Set up environment variables if not already set\n",
       "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
       "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
       "\n",
       "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
       "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")\n",
       "\n",
       "os.environ[\"USER_AGENT\"] = \"rag-ingestion-pipeline/1.0\""
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
       "from document_loaders import (\n",
       "    load_web_document,\n",
       "    load_pdf_document,\n",
       "    load_google_drive_document,\n",
       "    load_dynamic_web_document\n",
       ")\n",
       "from vector_store import VectorStoreManager\n",
       "from rag_pipeline import RAGPipeline\n",
       "\n",
       "# Initialize models\n",
       "llm = ChatOpenAI()\n",
       "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
       "\n",
       "# Initialize vector store manager\n",
       "vector_store = VectorStoreManager(embedding_model)\n",
       "\n",
       "# Try to load existing store or create new one\n",
       "vector_store_path = \"/Users/jsouthin/Projects/rag/faiss_index\"\n",
       "try:\n",
       "    vector_store.load_store(\n",
       "        vector_store_path,\n",
       "        allow_dangerous_deserialization=True\n",
       "    )\n",
       "    print(f\"Loaded existing vector store with {vector_store.document_count} documents\")\n",
       "except FileNotFoundError:\n",
       "    print(\"No existing vector store found. Will create new one.\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load documents\n",
       "project_id = \"my_first_project\"\n",
       "\n",
       "all_docs = load_dynamic_web_document(\n",
       "    [\"https://www.greatyellow.earth\", \"https://www.greatyellow.earth/about\"],\n",
       "    project_id=project_id\n",
       ") + load_pdf_document(\n",
       "    [\n",
       "        \"/Users/jsouthin/Documents/Joe Southin - CV 2025 (A4).pdf\",\n",
       "        \"/Users/jsouthin/Downloads/joe southin cv 2016.pdf\"\n",
       "    ],\n",
       "    project_id=project_id\n",
       ") + load_google_drive_document(\n",
       "    [\"1xCW-ZiquUxwBLpMTn9kL6WrvPlfeBYpDuicQhiIR81w\"],\n",
       "    \"/Users/jsouthin/Downloads/lively-tensor-432422-c0-407d22e805d2.json\",\n",
       "    project_id=project_id\n",
       ")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Initialize RAG pipeline\n",
       "rag = RAGPipeline(vector_store, llm)\n",
       "\n",
       "# Add documents to pipeline (this will handle chunking and vector store updates)\n",
       "rag.add_documents(all_docs)\n",
       "\n",
       "# Save updated vector store\n",
       "vector_store.save_store(vector_store_path, force=True)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Test some queries\n",
       "questions = [\n",
       "    \"explain the differences between a type 1, 2, and 3 model\",\n",
       "    \"why the name Great Yellow?\",\n",
       "    \"What is joe southin's biggest accomplishment?\"\n",
       "]\n",
       "\n",
       "for question in questions:\n",
       "    print(f\"Q: {question}\")\n",
       "    answer = rag.query(question, project_id)\n",
       "    print(f\"A: {answer}\\n\")"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }