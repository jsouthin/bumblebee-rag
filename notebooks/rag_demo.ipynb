{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d75ff9e",
   "metadata": {},
   "source": [
    "# LangChain + OpenAI RAG Proof of Concept\n",
    "## Overview\n",
    "* Collates provided sources into local vector store\n",
    "* Persists store for future recovery\n",
    "* Identifies relevant chunks and constructs prompt to send to OpenAI\n",
    "### Dependencies\n",
    "* User account for OpenAI and LangSmith\n",
    "* API keys from OpenAI and LangSmith\n",
    "* Main python dependencies:\n",
    "  * LangChain: langchain-openai langchain-core langchain-text-splitters langchain-community langgraph langchain[openai]\n",
    "  * GDrive: google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-google-community\n",
    "  * Web: bs4 unstructured selenium\n",
    "* Add the following to `~/.bash_profile` or `~/.zprofile` if `~/.zshrc`\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_ENDPOINT=\"https://{langsmith_region}.api.smith.langchain.com\"\n",
    "export LANGSMITH_API_KEY=\"{your_langsmith_api_key}\"\n",
    "export OPENAI_API_KEY=\"{your_openai_api_key}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39abaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Set up environment variables if not already set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"rag-ingestion-pipeline/1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a029b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded from '/Users/jsouthin/Projects/rag/faiss_index'.\n",
      "Loaded existing vector store with 673 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from document_loaders import (\n",
    "    load_web_document,\n",
    "    load_pdf_document,\n",
    "    load_google_drive_document,\n",
    "    load_dynamic_web_document\n",
    ")\n",
    "from vector_store import VectorStoreManager\n",
    "from rag_pipeline import RAGPipeline\n",
    "\n",
    "# Initialize models\n",
    "llm = ChatOpenAI()\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize vector store manager\n",
    "vector_store = VectorStoreManager(embedding_model)\n",
    "\n",
    "# Try to load existing store or create new one\n",
    "vector_store_path = \"/Users/jsouthin/Projects/rag/faiss_index\"\n",
    "try:\n",
    "    vector_store.load_store(\n",
    "        vector_store_path,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f\"Loaded existing vector store with {vector_store.document_count} documents\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing vector store found. Will create new one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661ea77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
      "/Users/jsouthin/Projects/rag/document_loaders.py:146: LangChainDeprecationWarning: The class `GoogleDriveLoader` was deprecated in LangChain 0.0.32 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-google-community package and should be used instead. To use it run `pip install -U :class:`~langchain-google-community` and import as `from :class:`~langchain_google_community import GoogleDriveLoader``.\n",
      "  loader = GoogleDriveLoader(\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "project_id = \"my_first_project\"\n",
    "\n",
    "all_docs = load_dynamic_web_document(\n",
    "    [\"https://www.greatyellow.earth\", \"https://www.greatyellow.earth/about\"],\n",
    "    project_id=project_id\n",
    ") + load_pdf_document(\n",
    "    [\n",
    "        \"/Users/jsouthin/Documents/Joe Southin - CV 2025 (A4).pdf\",\n",
    "        \"/Users/jsouthin/Downloads/joe southin cv 2016.pdf\"\n",
    "    ],\n",
    "    project_id=project_id\n",
    ") + load_google_drive_document(\n",
    "    [\"1xCW-ZiquUxwBLpMTn9kL6WrvPlfeBYpDuicQhiIR81w\"],\n",
    "    \"/Users/jsouthin/Downloads/lively-tensor-432422-c0-407d22e805d2.json\",\n",
    "    project_id=project_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b35acf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store updated with 110 new documents.\n",
      "Vector store saved to '/Users/jsouthin/Projects/rag/faiss_index'.\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAG pipeline\n",
    "rag = RAGPipeline(vector_store, llm)\n",
    "\n",
    "# Add documents to pipeline (this will handle chunking and vector store updates)\n",
    "rag.add_documents(all_docs)\n",
    "\n",
    "# Save updated vector store\n",
    "vector_store.save_store(vector_store_path, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2059f308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: A type 3 model, also known as Campaign id OHE model, one hot encodes campaign id and client id columns as features. It generates inference for campaigns present in the training set from the previous week. Inference for campaigns not in the training set can be generated using a type 2 model, known as Customer id OHE model, which drops client_id and campaign_id columns during training.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: The name \"Great Yellow\" is inspired by the poignant symbol of the urgent need to protect and nurture biodiversity represented by the Great Yellow butterfly.\n",
      "\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: Joe Southin's biggest accomplishment is developing an ML-powered budget management solution using MultiRegressor with python data pipelines, optimizing spend allocation, and increasing customer retention, now managing $78M+ in annual ad-spend.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test some queries\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, project_id)\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f43b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: I don't know the specific differences between a type 1, 2, and 3 model.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: The name Great Yellow refers to a butterfly species called the Great Yellow Mormon. The name likely comes from its large size and bright yellow coloration. The specific reason for the name may vary depending on cultural or regional factors.\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: I'm sorry, I don't have enough information to determine Joe Southin's biggest accomplishment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat some queries, but this time change project such that the context is no longer available\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, \"some_other_project\")\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cadc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
