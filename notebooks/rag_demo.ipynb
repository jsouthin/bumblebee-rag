{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d75ff9e",
   "metadata": {},
   "source": [
    "# LangChain + OpenAI RAG Proof of Concept\n",
    "## Overview\n",
    "* Collates provided sources into local vector store\n",
    "* Persists store for future recovery\n",
    "* Identifies relevant chunks and constructs prompt to send to OpenAI\n",
    "### Dependencies\n",
    "* User account for OpenAI and LangSmith\n",
    "* API keys from OpenAI and LangSmith\n",
    "* Main python dependencies:\n",
    "  * LangChain: langchain-openai langchain-core langchain-text-splitters langchain-community langgraph langchain[openai]\n",
    "  * GDrive: google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-google-community\n",
    "  * Web: bs4 unstructured selenium\n",
    "* Add the following to `~/.bash_profile` or `~/.zprofile` if `~/.zshrc`\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_ENDPOINT=\"https://{langsmith_region}.api.smith.langchain.com\"\n",
    "export LANGSMITH_API_KEY=\"{your_langsmith_api_key}\"\n",
    "export OPENAI_API_KEY=\"{your_openai_api_key}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39abaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up environment variables if not already set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"rag-ingestion-pipeline/1.0\"\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = Path().absolute().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f196dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
      "/Users/jsouthin/Projects/bumblebee-rag/src/document_loaders.py:147: LangChainDeprecationWarning: The class `GoogleDriveLoader` was deprecated in LangChain 0.0.32 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-google-community package and should be used instead. To use it run `pip install -U :class:`~langchain-google-community` and import as `from :class:`~langchain_google_community import GoogleDriveLoader``.\n",
      "  loader = GoogleDriveLoader(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from src.document_loaders import (\n",
    "    load_web_document,\n",
    "    load_pdf_document,\n",
    "    load_google_drive_document,\n",
    "    load_dynamic_web_document,\n",
    "    load_carbon_intensity\n",
    ")\n",
    "from src.vector_store import VectorStoreManager\n",
    "from src.rag_pipeline import RAGPipeline\n",
    "\n",
    "# Load all documents first\n",
    "project_id = \"my_first_project\"\n",
    "all_docs = load_dynamic_web_document(\n",
    "    [\"https://www.greatyellow.earth\", \"https://www.greatyellow.earth/about\"],\n",
    "    project_id=project_id\n",
    ") + load_pdf_document(\n",
    "    [\n",
    "        \"/Users/jsouthin/Documents/Joe Southin - CV 2025 (A4).pdf\",\n",
    "        \"/Users/jsouthin/Downloads/joe southin cv 2016.pdf\"\n",
    "    ],\n",
    "    project_id=project_id\n",
    ") + load_google_drive_document(\n",
    "    [\"1xCW-ZiquUxwBLpMTn9kL6WrvPlfeBYpDuicQhiIR81w\"],\n",
    "    \"/Users/jsouthin/Downloads/lively-tensor-432422-c0-407d22e805d2.json\",\n",
    "    project_id=project_id\n",
    ") + load_carbon_intensity(project_id=project_id)\n",
    "\n",
    "print(f\"Loaded {len(all_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2125a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing vector store found. Will create new one.\n",
      "Initialized new vector store with first document\n",
      "Vector store updated with 105 new documents.\n",
      "Vector store saved to '/Users/jsouthin/Projects/bumblebee-rag/data/faiss_index'.\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "llm = ChatOpenAI()\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize vector store manager\n",
    "vector_store = VectorStoreManager(embedding_model)\n",
    "\n",
    "# Try to load existing store or create new one\n",
    "vector_store_path = f\"{project_root}/data/faiss_index\"\n",
    "try:\n",
    "    vector_store.load_store(\n",
    "        vector_store_path,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f\"Loaded existing vector store with {vector_store.document_count} documents\")\n",
    "    remaining_docs = all_docs  # All docs need to be added if we loaded existing store\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing vector store found. Will create new one.\")\n",
    "    # Initialize with first document\n",
    "    vector_store.init_store([all_docs[0]])\n",
    "    # Remove the first document since it's already added\n",
    "    remaining_docs = all_docs[1:]\n",
    "    print(\"Initialized new vector store with first document\")\n",
    "\n",
    "# Initialize RAG pipeline\n",
    "rag = RAGPipeline(vector_store, llm)\n",
    "\n",
    "# Add remaining documents to pipeline\n",
    "if remaining_docs:\n",
    "    rag.add_documents(remaining_docs)\n",
    "\n",
    "# Save updated vector store\n",
    "vector_store.save_store(vector_store_path, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2059f308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: A type 3 model is also known as the Campaign id OHE model, featuring one-hot encoded campaign id and client id columns, while a type 2 model is the Customer id OHE model, with pca_id column encoded and client_id/campaign_id columns dropped. Type 3 models generate inference for campaigns in the training set, while Type 2 models handle campaigns not present in the training set. Note: Type 1 model is not an ML model but a technique implemented within the inference job.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: The name Great Yellow is inspired by the Great Yellow bumblebee, symbolizing the beauty and fragility of nature and the need to protect biodiversity. The company aims to demonstrate the economic value of thriving natural systems and the importance of regenerative practices. The Great Yellow bumblebee is a poignant symbol representing the urgent need to protect and nurture biodiversity in our natural world.\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: Joe Southin's biggest accomplishment is developing an ML-powered budget management solution using MultiRegressor with python data pipelines, optimizing spend allocation and increasing customer retention, now managing $78M+ in annual ad-spend.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test some queries\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, project_id)\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f43b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: I'm sorry, I don't have enough information to answer that question.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: The name \"Great Yellow\" is likely derived from the color yellow being associated with happiness, positivity, and energy. The addition of \"Great\" could indicate that this name represents a larger or more significant version of the color yellow. Overall, the name \"Great Yellow\" may suggest a powerful, vibrant, and impactful presence.\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: Joe Southin's biggest accomplishment is becoming the first person to successfully climb Mount Everest without the use of supplemental oxygen in 1988.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat some queries, but this time change project such that the context is no longer available\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, \"some_other_project\")\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7ea49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The carbon intensity index measures the amount of carbon emissions produced per unit of energy consumed. In the context provided, the carbon intensity index for the current half-hour period was 116, falling under the category of moderate according to the index scale.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.query('whats the carbon intensity index?', project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa78a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
