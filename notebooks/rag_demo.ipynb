{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d75ff9e",
   "metadata": {},
   "source": [
    "# LangChain + OpenAI RAG Proof of Concept\n",
    "## Overview\n",
    "* Collates provided sources into local vector store\n",
    "* Persists store for future recovery\n",
    "* Identifies relevant chunks and constructs prompt to send to OpenAI\n",
    "### Dependencies\n",
    "* User account for OpenAI and LangSmith\n",
    "* API keys from OpenAI and LangSmith\n",
    "* Main python dependencies:\n",
    "  * LangChain: langchain-openai langchain-core langchain-text-splitters langchain-community langgraph langchain[openai]\n",
    "  * GDrive: google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-google-community\n",
    "  * Web: bs4 unstructured selenium\n",
    "* Add the following to `~/.bash_profile` or `~/.zprofile` if `~/.zshrc`, or alternatively define these in a `.env` file in the root directory, ensure it's ignored in `.gitignore` and review `config.example.env` for example\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_ENDPOINT=\"https://{langsmith_region}.api.smith.langchain.com\"\n",
    "export LANGSMITH_API_KEY=\"{your_langsmith_api_key}\"\n",
    "export OPENAI_API_KEY=\"{your_openai_api_key}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df01692e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "   \n",
    "# Try to load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb90a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up environment variables if not already set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"rag-ingestion-pipeline/1.0\"\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = Path().absolute().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f196dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
      "/Users/jsouthin/Projects/bumblebee-rag/src/document_loaders.py:174: LangChainDeprecationWarning: The class `GoogleDriveLoader` was deprecated in LangChain 0.0.32 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-google-community package and should be used instead. To use it run `pip install -U :class:`~langchain-google-community` and import as `from :class:`~langchain_google_community import GoogleDriveLoader``.\n",
      "  loader = GoogleDriveLoader(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from src.document_loaders import (\n",
    "    load_web_document,\n",
    "    load_pdf_document,\n",
    "    load_google_drive_document,\n",
    "    load_dynamic_web_document,\n",
    "    load_carbon_intensity\n",
    ")\n",
    "from src.vector_store import VectorStoreManager\n",
    "from src.rag_pipeline import RAGPipeline\n",
    "\n",
    "# Load all documents first\n",
    "project_id = \"my_first_project\"\n",
    "all_docs = load_dynamic_web_document(\n",
    "    [\"https://www.greatyellow.earth\", \"https://www.greatyellow.earth/about\"],\n",
    "    project_id=project_id\n",
    ") + load_pdf_document(\n",
    "    [\n",
    "        \"/Users/jsouthin/Documents/Joe Southin - CV 2025 (A4).pdf\",\n",
    "        \"/Users/jsouthin/Downloads/joe southin cv 2016.pdf\"\n",
    "    ],\n",
    "    project_id=project_id\n",
    ") + load_google_drive_document(\n",
    "    [\"1xCW-ZiquUxwBLpMTn9kL6WrvPlfeBYpDuicQhiIR81w\"],\n",
    "    \"/Users/jsouthin/Downloads/lively-tensor-432422-c0-407d22e805d2.json\",\n",
    "    project_id=project_id\n",
    ") + load_carbon_intensity(project_id=project_id)\n",
    "\n",
    "print(f\"Loaded {len(all_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2125a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing vector store found. Will create new one.\n",
      "Initialized new vector store with first document\n",
      "Vector store updated with 104 new documents.\n",
      "Vector store updated with 1 new documents.\n",
      "Vector store saved to '/Users/jsouthin/Projects/bumblebee-rag/data/faiss_index'.\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "llm = ChatOpenAI()\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize vector store manager\n",
    "vector_store = VectorStoreManager(embedding_model)\n",
    "\n",
    "# Try to load existing store or create new one\n",
    "vector_store_path = f\"{project_root}/data/faiss_index\"\n",
    "try:\n",
    "    vector_store.load_store(\n",
    "        vector_store_path\n",
    "    )\n",
    "    print(f\"Loaded existing vector store with {vector_store.document_count} documents\")\n",
    "    remaining_docs = all_docs  # All docs need to be added if we loaded existing store\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing vector store found. Will create new one.\")\n",
    "    # Initialize with first document\n",
    "    vector_store.init_store([all_docs[0]])\n",
    "    # Remove the first document since it's already added\n",
    "    remaining_docs = all_docs[1:]\n",
    "    print(\"Initialized new vector store with first document\")\n",
    "\n",
    "# Initialize RAG pipeline\n",
    "rag = RAGPipeline(vector_store, llm)\n",
    "\n",
    "# Add remaining documents to pipeline\n",
    "if remaining_docs:\n",
    "    rag.add_documents(remaining_docs)\n",
    "\n",
    "# Save updated vector store\n",
    "vector_store.save_store(vector_store_path, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2059f308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: A Type 1 model in the context refers to supporting the concept of \"passthrough,\" where publisher simulations are used as-is with minor transformations. Type 2 and Type 3 models, on the other hand, involve OHE encoding of different columns like campaign_id and client_id for generating inference and simulations. Type 3 models are considered more granular and can perform better than Type 2 models, which serve as a fallback option.\n",
      "\n",
      "Q: what is Great Yellow?\n",
      "A: Great Yellow is a bumblebee species that symbolizes the beauty and fragility of nature, clinging to survival in the wildest parts of the UK due to habitat loss. Great Yellow Ltd draws inspiration from this bee to promote nature restoration and emphasize the economic value of thriving natural ecosystems.\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: Joe Southin's biggest accomplishment includes developing an ML-powered budget management solution that optimized spend allocation, leading to increased customer retention and managing over $78M in annual ad-spend. Additionally, he developed a bidding algorithm for Trip Advisor that saved approximately $1.3m in advertising costs per month and generated over $1.8m in revenue for the company. Southin also innovated a self-service automated tool for auditing customer accounts, resulting in a 26% performance uplift across clients and substantial time savings equivalent to 33 full-time employees.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test some queries\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"what is Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, project_id)\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f43b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: A type 1 model is a basic model that includes only one variable, while a type 2 model incorporates multiple variables but does not account for interactions between them. In contrast, a type 3 model considers interactions between variables, making it more complex and capable of capturing nonlinear relationships. Each type of model offers different levels of complexity and predictive power based on the relationships it can represent.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: I don't know the reason for the name \"Great Yellow.\"\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: Joe Southin's biggest accomplishment is becoming the first person to successfully climb Mount Everest without the use of supplemental oxygen in 1988.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat some queries, but this time change project such that the context is no longer available\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, \"some_other_project\")\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7ea49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Carbon Intensity for the current half hour is as follows:\n",
      "From: 2025-05-21T13:00Z\n",
      "To: 2025-05-21T13:30Z\n",
      "Forecast: 66\n",
      "Actual: 75\n",
      "Index: low.\n"
     ]
    }
   ],
   "source": [
    "print(rag.query('what is the Current Carbon Intensity for current half hour', project_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbac63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store saved to '/Users/jsouthin/Projects/bumblebee-rag/data/faiss_index'.\n"
     ]
    }
   ],
   "source": [
    "#Finally resave the store to update the checksum before closing\n",
    "vector_store.save_store(vector_store_path, force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
