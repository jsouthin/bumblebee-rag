{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d75ff9e",
   "metadata": {},
   "source": [
    "# LangChain + OpenAI RAG Proof of Concept\n",
    "## Overview\n",
    "* Collates provided sources into local vector store\n",
    "* Persists store for future recovery\n",
    "* Identifies relevant chunks and constructs prompt to send to OpenAI\n",
    "### Dependencies\n",
    "* User account for OpenAI and LangSmith\n",
    "* API keys from OpenAI and LangSmith\n",
    "* Main python dependencies:\n",
    "  * LangChain: langchain-openai langchain-core langchain-text-splitters langchain-community langgraph langchain[openai]\n",
    "  * GDrive: google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-google-community\n",
    "  * Web: bs4 unstructured selenium\n",
    "* Add the following to `~/.bash_profile` or `~/.zprofile` if `~/.zshrc`\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_ENDPOINT=\"https://{langsmith_region}.api.smith.langchain.com\"\n",
    "export LANGSMITH_API_KEY=\"{your_langsmith_api_key}\"\n",
    "export OPENAI_API_KEY=\"{your_openai_api_key}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39abaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up environment variables if not already set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"rag-ingestion-pipeline/1.0\"\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = Path().absolute().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f196dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
      "/Users/jsouthin/Projects/rag/src/document_loaders.py:147: LangChainDeprecationWarning: The class `GoogleDriveLoader` was deprecated in LangChain 0.0.32 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-google-community package and should be used instead. To use it run `pip install -U :class:`~langchain-google-community` and import as `from :class:`~langchain_google_community import GoogleDriveLoader``.\n",
      "  loader = GoogleDriveLoader(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from src.document_loaders import (\n",
    "    load_web_document,\n",
    "    load_pdf_document,\n",
    "    load_google_drive_document,\n",
    "    load_dynamic_web_document,\n",
    "    load_carbon_intensity\n",
    ")\n",
    "from src.vector_store import VectorStoreManager\n",
    "from src.rag_pipeline import RAGPipeline\n",
    "\n",
    "# Load all documents first\n",
    "project_id = \"my_first_project\"\n",
    "all_docs = load_dynamic_web_document(\n",
    "    [\"https://www.greatyellow.earth\", \"https://www.greatyellow.earth/about\"],\n",
    "    project_id=project_id\n",
    ") + load_pdf_document(\n",
    "    [\n",
    "        \"/Users/jsouthin/Documents/Joe Southin - CV 2025 (A4).pdf\",\n",
    "        \"/Users/jsouthin/Downloads/joe southin cv 2016.pdf\"\n",
    "    ],\n",
    "    project_id=project_id\n",
    ") + load_google_drive_document(\n",
    "    [\"1xCW-ZiquUxwBLpMTn9kL6WrvPlfeBYpDuicQhiIR81w\"],\n",
    "    \"/Users/jsouthin/Downloads/lively-tensor-432422-c0-407d22e805d2.json\",\n",
    "    project_id=project_id\n",
    ") + load_carbon_intensity(project_id=project_id)\n",
    "\n",
    "print(f\"Loaded {len(all_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2125a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded from './data/faiss_index'.\n",
      "Loaded existing vector store with 436 documents\n",
      "Vector store updated with 111 new documents.\n",
      "Vector store saved to './data/faiss_index'.\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "llm = ChatOpenAI()\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize vector store manager\n",
    "vector_store = VectorStoreManager(embedding_model)\n",
    "\n",
    "# Try to load existing store or create new one\n",
    "vector_store_path = \"./data/faiss_index\"\n",
    "try:\n",
    "    vector_store.load_store(\n",
    "        vector_store_path,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f\"Loaded existing vector store with {vector_store.document_count} documents\")\n",
    "    remaining_docs = all_docs  # All docs need to be added if we loaded existing store\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing vector store found. Will create new one.\")\n",
    "    # Initialize with first document\n",
    "    vector_store.init_store([all_docs[0]])\n",
    "    # Remove the first document since it's already added\n",
    "    remaining_docs = all_docs[1:]\n",
    "    print(\"Initialized new vector store with first document\")\n",
    "\n",
    "# Initialize RAG pipeline\n",
    "rag = RAGPipeline(vector_store, llm)\n",
    "\n",
    "# Add remaining documents to pipeline\n",
    "if remaining_docs:\n",
    "    rag.add_documents(remaining_docs)\n",
    "\n",
    "# Save updated vector store\n",
    "vector_store.save_store(vector_store_path, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2059f308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: The type 3 model is known as the Campaign id OHE model, where campaign id and client id columns are one hot encoded and used as features. It can generate inference for campaigns present in the previous week's training set. Inference for campaigns not in the training set can be done using the Type 2 model, also known as the Customer id OHE model, where the pca_id is encoded and client_id and campaign_id columns are dropped.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: The name Great Yellow is inspired by the Great Yellow butterfly, which serves as a symbol of the urgent need to protect biodiversity. Great Yellow Ltd aims to showcase the economic value of thriving natural systems, drawing inspiration from the Great Yellow butterfly.\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: Joe Southin's biggest accomplishment is developing an ML-powered budget management solution that optimized spend allocation and increased customer retention, now managing $78M+ in annual ad-spend.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test some queries\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, project_id)\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f43b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: I'm sorry, I don't have enough information to answer that question.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: The name \"Great Yellow\" might refer to the color yellow being associated with positivity, energy, and happiness. It could also be a creative or unique name chosen by the individual or company for branding purposes. Without further information, it is difficult to determine the specific reason behind the name \"Great Yellow.\"\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: I'm sorry, I don't have enough information to determine Joe Southin's biggest accomplishment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat some queries, but this time change project such that the context is no longer available\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, \"some_other_project\")\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7ea49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The carbon intensity index for the specified half-hour period is 154, with a forecasted value of 191. The index is categorized as moderate based on these values.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.query('whats the carbon intensity index?', project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa78a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
