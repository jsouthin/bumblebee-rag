{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d75ff9e",
   "metadata": {},
   "source": [
    "# LangChain + OpenAI RAG Proof of Concept\n",
    "## Overview\n",
    "* Collates provided sources into local vector store\n",
    "* Persists store for future recovery\n",
    "* Identifies relevant chunks and constructs prompt to send to OpenAI\n",
    "### Dependencies\n",
    "* User account for OpenAI and LangSmith\n",
    "* API keys from OpenAI and LangSmith\n",
    "* Main python dependencies:\n",
    "  * LangChain: langchain-openai langchain-core langchain-text-splitters langchain-community langgraph langchain[openai]\n",
    "  * GDrive: google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-google-community\n",
    "  * Web: bs4 unstructured selenium\n",
    "* Add the following to `~/.bash_profile` or `~/.zprofile` if `~/.zshrc`\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_ENDPOINT=\"https://{langsmith_region}.api.smith.langchain.com\"\n",
    "export LANGSMITH_API_KEY=\"{your_langsmith_api_key}\"\n",
    "export OPENAI_API_KEY=\"{your_openai_api_key}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39abaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up environment variables if not already set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"rag-ingestion-pipeline/1.0\"\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = Path().absolute().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a029b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing vector store found. Will create new one.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvector_store_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_dangerous_deserialization\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded existing vector store with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_store.document_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/rag/src/vector_store.py:71\u001b[39m, in \u001b[36mVectorStoreManager.load_store\u001b[39m\u001b[34m(self, path, force, allow_dangerous_deserialization)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path).exists():\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVector store path \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Vector store path 'data/faiss_index' does not exist.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo existing vector store found. Will create new one.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/rag/src/vector_store.py:25\u001b[39m, in \u001b[36mVectorStoreManager.init_store\u001b[39m\u001b[34m(self, docs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_store\u001b[39m(\u001b[38;5;28mself\u001b[39m, docs: List[Document]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     20\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize a new vector store with documents.\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m        docs: List of documents to initialize the store with\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28mself\u001b[39m._vector_store = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/rag/venv/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/rag/venv/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:1044\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1043\u001b[39m embeddings = embedding.embed_documents(texts)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/rag/venv/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:1001\u001b[39m, in \u001b[36mFAISS.__from\u001b[39m\u001b[34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[39m\n\u001b[32m    998\u001b[39m     index = faiss.IndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[32m0\u001b[39m]))\n\u001b[32m    999\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1000\u001b[39m     \u001b[38;5;66;03m# Default to L2, currently other metric types not initialized.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     index = faiss.IndexFlatL2(\u001b[38;5;28mlen\u001b[39m(\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[32m   1002\u001b[39m docstore = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mdocstore\u001b[39m\u001b[33m\"\u001b[39m, InMemoryDocstore())\n\u001b[32m   1003\u001b[39m index_to_docstore_id = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mindex_to_docstore_id\u001b[39m\u001b[33m\"\u001b[39m, {})\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from src.document_loaders import (\n",
    "    load_web_document,\n",
    "    load_pdf_document,\n",
    "    load_google_drive_document,\n",
    "    load_dynamic_web_document\n",
    ")\n",
    "from src.vector_store import VectorStoreManager\n",
    "from src.rag_pipeline import RAGPipeline\n",
    "\n",
    "# Initialize models\n",
    "llm = ChatOpenAI()\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize vector store manager\n",
    "vector_store = VectorStoreManager(embedding_model)\n",
    "\n",
    "# Try to load existing store or create new one\n",
    "vector_store_path = \"data/faiss_index\"\n",
    "try:\n",
    "    vector_store.load_store(\n",
    "        vector_store_path,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f\"Loaded existing vector store with {vector_store.document_count} documents\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing vector store found. Will create new one.\")\n",
    "    vector_store.init_store([])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661ea77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
      "/Users/jsouthin/Projects/rag/src/document_loaders.py:146: LangChainDeprecationWarning: The class `GoogleDriveLoader` was deprecated in LangChain 0.0.32 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-google-community package and should be used instead. To use it run `pip install -U :class:`~langchain-google-community` and import as `from :class:`~langchain_google_community import GoogleDriveLoader``.\n",
      "  loader = GoogleDriveLoader(\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "project_id = \"my_first_project\"\n",
    "\n",
    "all_docs = load_dynamic_web_document(\n",
    "    [\"https://www.greatyellow.earth\", \"https://www.greatyellow.earth/about\"],\n",
    "    project_id=project_id\n",
    ") + load_pdf_document(\n",
    "    [\n",
    "        \"/Users/jsouthin/Documents/Joe Southin - CV 2025 (A4).pdf\",\n",
    "        \"/Users/jsouthin/Downloads/joe southin cv 2016.pdf\"\n",
    "    ],\n",
    "    project_id=project_id\n",
    ") + load_google_drive_document(\n",
    "    [\"1xCW-ZiquUxwBLpMTn9kL6WrvPlfeBYpDuicQhiIR81w\"],\n",
    "    \"/Users/jsouthin/Downloads/lively-tensor-432422-c0-407d22e805d2.json\",\n",
    "    project_id=project_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b35acf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No vector store in memory. Load or initialize first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m rag = RAGPipeline(vector_store, llm)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Add documents to pipeline (this will handle chunking and vector store updates)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mrag\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Save updated vector store\u001b[39;00m\n\u001b[32m      8\u001b[39m vector_store.save_store(vector_store_path, force=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/rag/src/rag_pipeline.py:109\u001b[39m, in \u001b[36mRAGPipeline.add_documents\u001b[39m\u001b[34m(self, documents)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Add new documents to the vector store.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    documents: List of documents to add\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    108\u001b[39m splits = \u001b[38;5;28mself\u001b[39m.text_splitter.split_documents(documents)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/rag/src/vector_store.py:103\u001b[39m, in \u001b[36mVectorStoreManager.update_store\u001b[39m\u001b[34m(self, new_docs, save_path, force)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Update the vector store with new documents.\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \u001b[33;03m    RuntimeError: If no store is loaded\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._vector_store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo vector store in memory. Load or initialize first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    105\u001b[39m \u001b[38;5;28mself\u001b[39m._vector_store.add_documents(new_docs)\n\u001b[32m    106\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVector store updated with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m new documents.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: No vector store in memory. Load or initialize first."
     ]
    }
   ],
   "source": [
    "# Initialize RAG pipeline\n",
    "rag = RAGPipeline(vector_store, llm)\n",
    "\n",
    "# Add documents to pipeline (this will handle chunking and vector store updates)\n",
    "rag.add_documents(all_docs)\n",
    "\n",
    "# Save updated vector store\n",
    "vector_store.save_store(vector_store_path, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2059f308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: A type 3 model, also known as Campaign id OHE model, one hot encodes campaign id and client id columns as features. It generates inference for campaigns present in the training set from the previous week. Inference for campaigns not in the training set can be generated using a type 2 model, known as Customer id OHE model, which drops client_id and campaign_id columns during training.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: The name \"Great Yellow\" is inspired by the poignant symbol of the urgent need to protect and nurture biodiversity represented by the Great Yellow butterfly.\n",
      "\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: Joe Southin's biggest accomplishment is developing an ML-powered budget management solution using MultiRegressor with python data pipelines, optimizing spend allocation, and increasing customer retention, now managing $78M+ in annual ad-spend.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test some queries\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, project_id)\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f43b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: explain the differences between a type 1, 2, and 3 model\n",
      "A: I don't know the specific differences between a type 1, 2, and 3 model.\n",
      "\n",
      "Q: why the name Great Yellow?\n",
      "A: The name Great Yellow refers to a butterfly species called the Great Yellow Mormon. The name likely comes from its large size and bright yellow coloration. The specific reason for the name may vary depending on cultural or regional factors.\n",
      "\n",
      "Q: What is joe southin's biggest accomplishment?\n",
      "A: I'm sorry, I don't have enough information to determine Joe Southin's biggest accomplishment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat some queries, but this time change project such that the context is no longer available\n",
    "questions = [\n",
    "    \"explain the differences between a type 1, 2, and 3 model\",\n",
    "    \"why the name Great Yellow?\",\n",
    "    \"What is joe southin's biggest accomplishment?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    answer = rag.query(question, \"some_other_project\")\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cadc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
